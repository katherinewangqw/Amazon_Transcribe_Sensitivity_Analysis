{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# 350 Fontana Blog Post",
      "metadata": {
        "tags": [],
        "cell_id": "00001-97c913ce-32c7-4645-9276-c7f7145e2d4b",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Audio is a clear form of communication, but transcripts reinforce it. In this blog post, we would show how Amazon Transcribe is used to improve your experience of listening to music with lyrics. We start with an overview of the AWS Transcribe function, explained how various data and songs are collected and analyze data, and discussed real-word application of AWS Transcribe that facilitates our day to day.",
      "metadata": {
        "tags": [],
        "cell_id": "00001-643e65d2-c8fe-45a7-bf6c-d8e8f6dd1b94",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# AWS Transcribe Overview",
      "metadata": {
        "tags": [],
        "cell_id": "00002-aea42b15-5b00-4b44-9e24-8c4c5ec12f58",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "According to National Institute on Deafness and Other Communication Disorders [NIDCD](https://www.nidcd.nih.gov/health/statistics/quick-statistics-hearing), approximately 0.2 ~ 0.3% of children are born with a noticeable hearing loss level in one or both ears in the United States and about 37.5 million American adults report having trouble hearing. People with impaired hearing deserve a quality life and AWS Transcribe can help this out.\n\nAmazon Transcribe utilizes a deep learning process called automatic speech recognition (ASR) to convert speech to text accurately and effectively. It analyzes audio files and uses advanced machine learning technologies to transcribe voice data into texts. It can be used to transcribe phone calls, automate subtitling, and generate metadata for media assets to create a fully searchable archive. (ref: [aws-transcribe](https://aws.amazon.com/transcribe/))\n",
      "metadata": {
        "tags": [],
        "cell_id": "00003-2bb1570a-efe4-4864-aae2-e3bcda7daa00",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "![AWS transcribe](transcribe.png)",
      "metadata": {
        "tags": [],
        "cell_id": "00004-f24537a2-3f84-4817-a5a4-dc64a441dcff",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Motivation &amp; Aims of the Project",
      "metadata": {
        "tags": [],
        "cell_id": "00004-6162aa8e-0d61-4c2f-9814-5c02fbd85aa2",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "When comparing Apple Music and Spotify, Apple music took the lead in its live lyrics feature, which provides an on-screen, karaoke-style feature. It is not until March 2021 did Spotify finally released the new lyrics feature on its platform, partnered with Genius and Musicmatch. However, as the new lyrics feature is still in its testing phase, it has not covered all the songs on the platform. Indeed, Spotify has been receiving complaints from users that they cannot access the lyrics completely. So, unfortunately, users have to wait for the new real-time lyrics feature to catch up with the great amount of music available on the platform.",
      "metadata": {
        "tags": [],
        "cell_id": "00004-f880ed4a-1883-4f82-af84-84920fdba9c4",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Imagine a situation that you fall in love with a blue song in a foreign language and you are desperate to learn what it expresses, or, that you got ignited by a rap song but you can’t figure out what it’s rapping unless you have a real-time lyrics book on hand. In such situations, you would get mad staring at the blank lyrics page. That brings us the inspiration to generate lyrics on our own. Fortunately, with the help of Amazon Transcribe, we are able to achieve this goal.",
      "metadata": {
        "tags": [],
        "cell_id": "00005-2cf77174-4c0f-4ffb-852d-c41a632f139c",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "![music nerd](nerd.jpeg)",
      "metadata": {
        "tags": [],
        "cell_id": "00007-830a1f60-f477-49de-a171-f0690b816a72",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "The question that comes to mind spontaneously is that whether AWS Transcribe is capable of translating with high accuracy. Indeed, language is so delicately nuanced and contextual that it takes a lot of rules, reasoning, data, and processing power for people to understand. Spenser Mestel, writing in The Atlantic, points out that “Language is a data set that’s far more complex than it seems, so no matter how quickly translation technology evolves, the stochastic messiness of speech will always outpace it”. The limitation of machine translation is also experienced everywhere in daily life. When you watch a recording of a last week’s class that you missed, you may find that the professor speaks so fast with a tone that you just can’t get along with. However, when you turn on the auto-generated subtitle, you find it only makes things worse: API translated into “AP eyes” is just one of the numerous examples. So, imaginably, when translating songs with background instrumental “noises” and lyrics with speeds ranging from sighing to rapping, unexpected punctuation, and varying pitching, the performance of any machine learning translator could be very unpredictable. Therefore, in this project, through inputting numerous mp3 song files into the AWS Transcribe translator, we compare the generated lyrics with the correct lyrics, and summarize from the results what input factors influence the accuracy of AWS Transcribe’s work.",
      "metadata": {
        "tags": [],
        "cell_id": "00006-a96f4d3f-44d5-4f8f-94d4-39b1123118d1",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Among the factors of a song file that could influence the accuracy of Amazon Transcribe's work, there are sample rate and bit rate. In computer, digital audio is converted into information readable by a computer system. Certain characteristics of a sound wave, like the frequency and amplitude, are converted to binary data that computer software can read. Samples are the series of snapshots taken on the digital audio. A sample is taken at a particular time in the audio wave, recording amplitude. This information is then converted into binary data. The rate at which the samples are taken snapshot of is the&nbsp;sample rate, measured in kilohertz. Bit rate is, on the other hand, the number of bits in each sample, or, the rate at which bits are transferred from one location to another. More bits are used to represent the audio data for each second of playback, or, higher bit rate, usually corresponds to better sound quality. ",
      "metadata": {
        "tags": [],
        "cell_id": "00010-2dc70395-f7c2-4f7a-98c6-8da67095982e",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "![sample rate](samplerate.png)",
      "metadata": {
        "tags": [],
        "cell_id": "00010-37f8148e-e8ee-4eab-b9cf-bd92ee575221",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Accuracy and precision build credibility; so, it is vital to test how accurate AWS Transcribe is before applying it to music apps like Spotify. In order to test how accurately AWS Transcribe can transcribe songs to lyrics, we compute the Levenshtein Distance (LD) -- a number that informs people how similar two sequences are. The lower the given number is, the more similar the two sequences are. LD is named after Russian Scientist Vladimir Levenshtein who invented this algorithm in 1965. It is a popular and useful technique that has been used in fields like speech recognition, DNA analysis, and plagiarism detection. As we are comparing the generated lyrics with the correct lyrics, we will apply this algorithm as well. Matrices will be constructed to compute the LD; after that, we will analyze the numbers and determine whether AWS Transcribe can accurately generate lyrics.",
      "metadata": {
        "tags": [],
        "cell_id": "00009-0931b7f3-e101-49eb-b5a1-178c5aa99f03",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Steps of Using AWS Transcribe",
      "metadata": {
        "tags": [],
        "cell_id": "00003-569dd204-72eb-429b-a130-05641b458ba8",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Log in to your AWS account and select `amazon sagemaker`\n\n![Step 1](1.JPG)\n\nClick on `IAM role ARN` and you will see the following webpage\n\n![Step 2](2.JPG)\n\nSearch for `transcribe`\n\n![Step 3](3.JPG)\n\nSelect the policy named `AmazonTranscribeFullAccess` and attach it to your notebook instance\n\n![Step 4](4.JPG)",
      "metadata": {
        "tags": [],
        "cell_id": "00004-752f9b72-da8b-4b50-b3e4-6f56c7d03914",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Lyrics Fetch and Levenshtein Distance",
      "metadata": {
        "tags": [],
        "cell_id": "00013-da97a3ca-3caf-46ac-9f0f-aa678a4ea6c6",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Here, we display how to find the Levenshtein Distance that represents the accuracy of the translated lyrics compared to the true lyrics. We iterated through all music files in google drive and dropped songs without metadata. We used the lyrics.ovh API to retrieve the lyrics for the songs and did some formatting to display the true lyrics and transcribed lyrics in the table. ",
      "metadata": {
        "tags": [],
        "cell_id": "00014-34bd6a6d-26d0-4c6b-b611-826e29b0260b",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Here is a table containing the information about the 632 songs as well as their true lyrics and transcribed lyrics.",
      "metadata": {
        "tags": [],
        "cell_id": "00015-3156fd3e-af6d-4324-a529-842fd1db5bdf",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "![Song ](Song.png)",
      "metadata": {
        "tags": [],
        "cell_id": "00016-89fa1e1e-407d-4690-8c73-516bb5e31b33",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Levenshtein ratio and distance are computed to test the accuracy of AWS Transcribe. We first created a matrix and populated it with the indices of every character from the two strings (true lyrics and generated lyrics). After that, we iterate over the matrix to compute the cost of deletion, insertion, and substitution. In order to align the results with those of the Python Levenshtein package, the cost of a substitution would be 2 if we choose to calculate the ratio and the cost of a substitution would be 1 if we merely calculate the distance.",
      "metadata": {
        "tags": [],
        "cell_id": "00017-7c2e30d1-0bf7-44ce-9977-f17d3e0ecbca",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "We did two OLS Regression Models to test how bitrate, sample rate, tempo, and genre relates to the accuracy of AWS Transcribe. The first column of the figure below is the result of the first model, which contains Accuracy ~ Sample + Bitrate + Tempo. The second column is the result of the second model, which not only contains Accuracy ~ Sample + Bitrate + Tempo but also includes dummy-coded variable genre. ",
      "metadata": {
        "tags": [],
        "cell_id": "00022-199692b6-a13a-412f-bbd4-d44394513d58",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "![Genre ](Genre.png)",
      "metadata": {
        "tags": [],
        "cell_id": "00022-fafc4bdb-e7bc-4c88-a9f7-a1349fa6525a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "According to the result, we interpret that bitrate, sample rate, tempo, genre dance, and genre Hip Hop are positively correlated with accuracy when other covariates are controlled constant.  However, genre Pop, genre R&amp;B, genre Rock, and genre Films are negatively correlated with accuracy when other covariates are controlled constant. We have also discovered that genre In the following, we will give detailed analysis by plotting the accuracy with respect to the factors. ",
      "metadata": {
        "tags": [],
        "cell_id": "00023-cba415b1-81bb-4a9a-aab2-cc5ae0679aea",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Production and Analysis",
      "metadata": {
        "tags": [],
        "cell_id": "00013-b7e8ca68-8b5f-45f2-9c74-6d178b6d2167",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "We downloaded hundreds of songs from QQ Music through subscription.",
      "metadata": {
        "tags": [],
        "cell_id": "00015-83e74f26-4204-4e26-8bda-775c43270e7e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "We first retrieve the lyrics of our songs and format the information into a proper data frame, which is added to our s3 bucket. ",
      "metadata": {
        "tags": [],
        "cell_id": "00019-c2eaef5c-968e-45ab-896c-c6f306ceeaa1",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Bitrate, sample rate, genre, and tempo are factors that might influence the accuracy of translation. Nowt that we get a sense of how they influence the accuracy of Amazon Transcribe's performance, we take another sample of about 600 songs to further analyze the influence of sample rate, genre, tempo, together with bitrate, on the performance of Amazon Transcribe, by showing plots.\n\nHere is the retrieval of information of the songs. \n\n![code ](code2.png)\n\nThe information of the songs in the new sample are displayed as below:\n\n![dataframe2 ](newtable.png)",
      "metadata": {
        "tags": [],
        "cell_id": "00017-ff25b070-9903-48fa-a69b-54dec421a392",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "The correlation of tempo, bitrate, sample rate, and accuracy are shown in the heatmap:\n![heatmap ](heatmap2.png)\n\nDoing regression of accuracy on bitrate, we get:\n![accuracy_bitrate ](accuracy_bitrate.png)\n\nAs the regression line suggests, accuracy of Transcribe's performance increases with greater bitrate. This is intuitive, as greater bitrate usually implies better sound quailty. The negative correlation between accuracy and bitrate obtained in the previous session might be due to limitation of a small sample size.\n\nDoing regression of accuracy on sample rate, we get:\n![Accuracy v.s. Sample Rate ](accuracy_samplerate.png)\nThe regression line suggests a positive correlation between accuracy and sample rate. This also reinforces our notion that with higher sample rate, the audio properties are better captured by the computer. \n\nWe then plot accuracy v.s. tempo:\n![Accuracy v.s. Tempo ](accuracy_tempo.png)\nAs it shows, there is no remarkable relationship between accuracy and tempo. \n\nWhile we cannot treat genre as a quantitative variable, we do it categorically and analyze the distribution of accuracy in each genre:\n![Accuracy v.s. Genre](accuracy_genre.png)\nIt is interesting to observe that Amazon Transcribe works best with songs in rap/hip-hop genre. Is it  because rap songs are less melodic? That might be the answer. \n",
      "metadata": {
        "tags": [],
        "cell_id": "00018-549ad8be-d607-4517-a4a6-cadc01480974",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Architecture Overview",
      "metadata": {
        "tags": [],
        "cell_id": "00025-9b7d62f9-c0f5-4b3d-9bf0-118221f9ea77",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "![Architecture ](Architecture.png)",
      "metadata": {
        "tags": [],
        "cell_id": "00032-f6946ab3-535e-473b-99c4-46f647d719f3",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "To summarize our project, as illustrated with the AWS architecture graph above, we collected and processed multiple audio data, stored them through S3 bucket, and used AWS Transcribe with Amazon Sagemaker as a channel to perform our analysis. Finally, outputs are passed on to final synthesis and analysis.",
      "metadata": {
        "tags": [],
        "cell_id": "00033-2c0c1f00-4c4a-4225-8337-1d5c0421af06",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Conclusion &amp; Discussions ",
      "metadata": {
        "tags": [],
        "cell_id": "00023-07a95b3d-e195-4f14-8054-9aa5612b1dca",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "In this blog post, we illustrated how to use Amazon Transcribe to genereate lyrics from different songs and tested its accuracy and reliability. \n\nAs shown in the output, at a significant level of 99%, correlations between bitrate and accuracy and sample rate and accuracy are found whereas no significant correlation between tempo and accuracy is shown. For different genres, Amazon Transcribe's performed the best with Hip Pop music and it is most susceptible when applying to Rock music. The accuracy of retrieving correct lyrics depends on multiple regressors including bitrate, sample rate, genre of the song, and tempo of the song. The accuracy rate is on average is reported to be 40% on average. However, since our input data was compressed randomly, they have various quality of bitrate and sample rate. Normally, audio we obtain through online resources have relative high quality that their bitrates are typically in the range of 192k to 320 k and sample rate are higher than 44100. Thus, we believe the 75% percentile accuracy at 63.9% would be a good reference for a normal performance of Amazon Transcribe. A rate at 63.9% indicats a general reliability for retriving instant transcription, saving labor input and facilitating those who have difficulties hearing words appropriately. \n\nThere are some limitations discovered when experimenting AWS Transcribe. First of all, the sample we used is not generalized enough -- we only tested Top 100 English Songs from Billboard over 7 years. Therefore, we don't know how accurate AWS Transcribe will retrieve lyrics for songs in other languages and for songs that are not as popular as Top 100 Billboard songs. Secondly, we only examined how 4 factors (bitrate, sample rate, genre of the song, and tempo of the song) relating to accuracy and we found that song tempo would not affect the accuracy largely. There might exist other factors that could be tested and explored to improve the accuracy of AWS Transcribe while transcribing lyrics. Lastly, we also postulate that AWS Transcribe may not be originally trained for retrieving lyrics given its performance of accuracy.",
      "metadata": {
        "tags": [],
        "cell_id": "00024-8325cf77-64da-4aaf-8984-7215ad4dadee",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Citations",
      "metadata": {
        "tags": [],
        "cell_id": "00011-ce8420ad-3297-44f2-8bdf-2a8716cdff08",
        "deepnote_cell_type": "text-cell-h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": "https://www.rtinsights.com/real-time-translation-machine-challenges/",
      "metadata": {
        "tags": [],
        "cell_id": "00011-8fa1ba18-5914-49fc-85ba-a0c854814722",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "https://www.dreamstime.com/photos-images/music-nerd.html",
      "metadata": {
        "tags": [],
        "cell_id": "00032-084a295d-355b-4400-adf8-72cab56663bf",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "https://www.izotope.com/en/learn/digital-audio-basics-sample-rate-and-bit-depth.html",
      "metadata": {
        "tags": [],
        "cell_id": "00018-49b5b6d4-b85b-43b0-9e74-8244db1dabc4",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=34182c1e-ced2-433c-9676-54ec654bbd88' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "f8bfcd03-ec9c-4b5d-a6c3-b0f8d7db8ff2",
    "deepnote_execution_queue": []
  }
}